{
  "name": "bespoke-ai",
  "displayName": "Bespoke AI",
  "description": "Inline ghost-text completions for prose and code using Anthropic Claude or Ollama",
  "version": "0.1.0",
  "publisher": "trenthm",
  "icon": "images/icon.png",
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "bespoke-ai.trigger",
        "title": "Bespoke AI: Trigger Completion"
      },
      {
        "command": "bespoke-ai.toggleEnabled",
        "title": "Bespoke AI: Toggle Enabled"
      },
      {
        "command": "bespoke-ai.cycleMode",
        "title": "Bespoke AI: Cycle Mode"
      },
      {
        "command": "bespoke-ai.clearCache",
        "title": "Bespoke AI: Clear Completion Cache"
      },
      {
        "command": "bespoke-ai.selectProfile",
        "title": "Bespoke AI: Select Profile"
      },
      {
        "command": "bespoke-ai.showMenu",
        "title": "Bespoke AI: Show Menu"
      },
      {
        "command": "bespoke-ai.generateCommitMessage",
        "title": "Bespoke AI: Generate Commit Message",
        "icon": "$(sparkle)"
      }
    ],
    "menus": {
      "scm/title": [
        {
          "command": "bespoke-ai.generateCommitMessage",
          "group": "navigation",
          "when": "scmProvider == git"
        }
      ]
    },
    "keybindings": [
      {
        "command": "bespoke-ai.trigger",
        "key": "ctrl+l",
        "mac": "ctrl+l",
        "when": "editorTextFocus"
      }
    ],
    "configuration": {
      "title": "Bespoke AI",
      "properties": {
        "bespokeAI.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable or disable inline completions"
        },
        "bespokeAI.backend": {
          "type": "string",
          "enum": [
            "claude-code",
            "anthropic",
            "ollama"
          ],
          "default": "claude-code",
          "description": "Backend provider for completions"
        },
        "bespokeAI.mode": {
          "type": "string",
          "enum": [
            "auto",
            "prose",
            "code"
          ],
          "default": "auto",
          "description": "Completion mode (auto detects based on file type)"
        },
        "bespokeAI.debounceMs": {
          "type": "number",
          "default": 300,
          "description": "Delay in milliseconds before triggering completion"
        },
        "bespokeAI.anthropic.apiKey": {
          "type": "string",
          "default": "",
          "description": "Anthropic API key for Claude completions"
        },
        "bespokeAI.anthropic.model": {
          "type": "string",
          "default": "claude-haiku-4-5-20251001",
          "description": "Anthropic model to use. See anthropic.models for available options."
        },
        "bespokeAI.anthropic.models": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "claude-haiku-4-5-20251001",
            "claude-sonnet-4-20250514",
            "claude-opus-4-20250514"
          ],
          "description": "Available Anthropic models. The active model is set in anthropic.model."
        },
        "bespokeAI.anthropic.useCaching": {
          "type": "boolean",
          "default": true,
          "description": "Enable prompt caching for cost savings"
        },
        "bespokeAI.anthropic.apiCallsEnabled": {
          "type": "boolean",
          "default": true,
          "description": "Safety switch to disable all direct Anthropic API calls"
        },
        "bespokeAI.ollama.endpoint": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "Ollama API endpoint URL"
        },
        "bespokeAI.ollama.model": {
          "type": "string",
          "default": "qwen2.5:3b",
          "description": "Ollama model to use. See ollama.models for available options."
        },
        "bespokeAI.ollama.models": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "qwen2.5:3b",
            "qwen2.5-coder:3b",
            "llama3.2:3b",
            "deepseek-coder-v2:latest"
          ],
          "description": "Available Ollama models. The active model is set in ollama.model."
        },
        "bespokeAI.ollama.raw": {
          "type": "boolean",
          "default": true,
          "description": "Use raw mode (bypasses chat template, for base models)"
        },
        "bespokeAI.claudeCode.model": {
          "type": "string",
          "default": "haiku",
          "description": "Claude Code model to use (e.g. haiku, sonnet, opus)"
        },
        "bespokeAI.claudeCode.models": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "haiku",
            "sonnet",
            "opus"
          ],
          "description": "Available Claude Code models. The active model is set in claudeCode.model."
        },
        "bespokeAI.prose.maxTokens": {
          "type": "number",
          "default": 100,
          "description": "Maximum tokens for prose completions"
        },
        "bespokeAI.prose.temperature": {
          "type": "number",
          "default": 0.7,
          "description": "Temperature for prose completions"
        },
        "bespokeAI.prose.stopSequences": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "\n\n",
            "---",
            "##"
          ],
          "description": "Stop sequences for prose completions"
        },
        "bespokeAI.prose.contextChars": {
          "type": "number",
          "default": 2000,
          "description": "Number of prefix characters to include for prose context"
        },
        "bespokeAI.prose.suffixChars": {
          "type": "number",
          "default": 500,
          "description": "Number of suffix characters (after cursor) to include for prose context"
        },
        "bespokeAI.prose.fileTypes": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "markdown",
            "plaintext"
          ],
          "description": "Language IDs treated as prose"
        },
        "bespokeAI.code.maxTokens": {
          "type": "number",
          "default": 256,
          "description": "Maximum tokens for code completions"
        },
        "bespokeAI.code.temperature": {
          "type": "number",
          "default": 0.2,
          "description": "Temperature for code completions"
        },
        "bespokeAI.code.stopSequences": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "\n\n"
          ],
          "description": "Stop sequences for code completions"
        },
        "bespokeAI.code.contextChars": {
          "type": "number",
          "default": 4000,
          "description": "Number of prefix characters to include for code context"
        },
        "bespokeAI.code.suffixChars": {
          "type": "number",
          "default": 500,
          "description": "Number of suffix characters (after cursor) to include for code context"
        },
        "bespokeAI.logLevel": {
          "type": "string",
          "enum": [
            "info",
            "debug",
            "trace"
          ],
          "default": "info",
          "description": "Logging verbosity in the Output channel"
        },
        "bespokeAI.oracle.enabled": {
          "type": "boolean",
          "default": false,
          "description": "Enable context oracle for richer completions (requires claude CLI + Agent SDK)"
        },
        "bespokeAI.oracle.debounceMs": {
          "type": "number",
          "default": 2000,
          "description": "Delay after file events before triggering oracle analysis"
        },
        "bespokeAI.oracle.briefTtlMs": {
          "type": "number",
          "default": 300000,
          "description": "Context brief expiry in milliseconds"
        },
        "bespokeAI.oracle.model": {
          "type": "string",
          "default": "sonnet",
          "description": "Model for oracle analysis session"
        },
        "bespokeAI.oracle.allowedTools": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [
            "Read",
            "Grep",
            "Glob"
          ],
          "description": "Tools the oracle agent can use"
        },
        "bespokeAI.profiles": {
          "type": "object",
          "default": {
            "haiku-fast": {
              "anthropic": {
                "model": "claude-haiku-4-5-20251001",
                "useCaching": true
              },
              "prose": {
                "maxTokens": 80,
                "temperature": 0.7,
                "stopSequences": [
                  "\n\n",
                  "---",
                  "##"
                ],
                "contextChars": 2000,
                "suffixChars": 500
              },
              "code": {
                "maxTokens": 200,
                "temperature": 0.2,
                "stopSequences": [
                  "\n\n"
                ],
                "contextChars": 4000,
                "suffixChars": 500
              }
            }
          },
          "description": "Named config profiles. Each key is a profile name, value is partial config to merge over base settings. The default 'haiku-fast' profile is a template showing all overridable fields.",
          "additionalProperties": {
            "type": "object",
            "properties": {
              "backend": {
                "type": "string",
                "enum": [
                  "claude-code",
                  "anthropic",
                  "ollama"
                ]
              },
              "mode": {
                "type": "string",
                "enum": [
                  "auto",
                  "prose",
                  "code"
                ]
              },
              "debounceMs": {
                "type": "number"
              },
              "logLevel": {
                "type": "string",
                "enum": [
                  "info",
                  "debug",
                  "trace"
                ]
              },
              "anthropic": {
                "type": "object",
                "properties": {
                  "model": {
                    "type": "string"
                  },
                  "useCaching": {
                    "type": "boolean"
                  }
                }
              },
              "ollama": {
                "type": "object",
                "properties": {
                  "endpoint": {
                    "type": "string"
                  },
                  "model": {
                    "type": "string"
                  },
                  "raw": {
                    "type": "boolean"
                  }
                }
              },
              "prose": {
                "type": "object",
                "properties": {
                  "maxTokens": {
                    "type": "number"
                  },
                  "temperature": {
                    "type": "number"
                  },
                  "stopSequences": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  },
                  "contextChars": {
                    "type": "number"
                  },
                  "suffixChars": {
                    "type": "number"
                  },
                  "fileTypes": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                }
              },
              "code": {
                "type": "object",
                "properties": {
                  "maxTokens": {
                    "type": "number"
                  },
                  "temperature": {
                    "type": "number"
                  },
                  "stopSequences": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  },
                  "contextChars": {
                    "type": "number"
                  },
                  "suffixChars": {
                    "type": "number"
                  }
                }
              },
              "oracle": {
                "type": "object",
                "properties": {
                  "enabled": {
                    "type": "boolean"
                  },
                  "debounceMs": {
                    "type": "number"
                  },
                  "briefTtlMs": {
                    "type": "number"
                  },
                  "model": {
                    "type": "string"
                  },
                  "allowedTools": {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                }
              },
              "claudeCode": {
                "type": "object",
                "properties": {
                  "model": {
                    "type": "string"
                  }
                }
              }
            }
          }
        },
        "bespokeAI.activeProfile": {
          "type": "string",
          "default": "",
          "description": "Name of the active profile (empty = use base settings)"
        },
        "bespokeAI.commitMessage.systemPrompt": {
          "type": "string",
          "default": "",
          "description": "Custom system prompt for commit message generation. Leave empty for the built-in prompt."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "node esbuild.js",
    "watch": "node esbuild.js --watch",
    "lint": "eslint src/",
    "check": "npm run lint && tsc --noEmit",
    "test": "npm run test:unit",
    "test:unit": "vitest run",
    "test:unit:watch": "vitest",
    "test:api": "vitest run --config vitest.api.config.ts",
    "test:quality": "vitest run --config vitest.quality.config.ts",
    "benchmark": "tsx src/benchmark/runner.ts"
  },
  "devDependencies": {
    "@types/node": "^20.11.0",
    "@types/vscode": "^1.85.0",
    "@typescript-eslint/eslint-plugin": "^8.54.0",
    "@typescript-eslint/parser": "^8.54.0",
    "esbuild": "^0.24.0",
    "eslint": "^9.39.2",
    "tsx": "^4.0.0",
    "typescript": "^5.3.0",
    "vitest": "^4.0.18"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.39.0"
  },
  "optionalDependencies": {
    "@anthropic-ai/claude-agent-sdk": "^0.1.77"
  }
}
